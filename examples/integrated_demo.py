"""
ç»¼åˆæ¼”ç¤ºç¨‹åº - å®Œæ•´çš„æ‰‹åŠ¿è¯†åˆ«æ§åˆ¶ç³»ç»Ÿ
å±•ç¤ºæ‰€æœ‰æ¨¡å—çš„é›†æˆä½¿ç”¨å’Œå®æ—¶æ‰‹åŠ¿æ§åˆ¶åŠŸèƒ½
"""

import cv2
import time
import numpy as np
import sys
import os
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

"""
ç»¼åˆæ¼”ç¤ºç¨‹åº - å®Œæ•´çš„æ‰‹åŠ¿è¯†åˆ«æ§åˆ¶ç³»ç»Ÿ
å±•ç¤ºæ‰€æœ‰æ¨¡å—çš„é›†æˆä½¿ç”¨å’Œå®æ—¶æ‰‹åŠ¿æ§åˆ¶åŠŸèƒ½
"""

import cv2
import time
import numpy as np
import sys
import os
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# æ·»åŠ æ¨¡å—è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'modules'))

try:
    from image_processing.image_processor import CameraCapture, ImageProcessor, ImageQualityAssessment, ImageVisualizer
    from pose_detection.pose_detector import PoseDetector, PoseVisualizer, PoseAnalyzer
    from distance_estimation.distance_estimator import DistanceEstimator, DistanceVisualizer
    from gesture_recognition.gesture_recognizer import GestureRecognizer, GestureVisualizer
except ImportError as e:
    print(f"æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿æ‰€æœ‰æ¨¡å—éƒ½åœ¨æ­£ç¡®çš„ä½ç½®")
    sys.exit(1)

class GestureControlSystem:
    """æ‰‹åŠ¿æ§åˆ¶ç³»ç»Ÿ - é›†æˆæ‰€æœ‰æ¨¡å—"""
    
    def __init__(self, camera_id=0):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        print("åˆå§‹åŒ–æ‰‹åŠ¿æ§åˆ¶ç³»ç»Ÿ...")
        
        # å›¾åƒå¤„ç†æ¨¡å—
        self.camera_capture = CameraCapture(camera_id=camera_id, width=640, height=480)
        self.image_processor = ImageProcessor()
        self.quality_assessor = ImageQualityAssessment()
        self.image_visualizer = ImageVisualizer()
        
        # å§¿åŠ¿æ£€æµ‹æ¨¡å—
        self.pose_detector = PoseDetector(model_complexity=1)
        self.pose_visualizer = PoseVisualizer()
        self.pose_analyzer = PoseAnalyzer()
        
        # è·ç¦»ä¼°ç®—æ¨¡å—
        self.distance_estimator = DistanceEstimator()
        self.distance_visualizer = DistanceVisualizer()
        
        # æ‰‹åŠ¿è¯†åˆ«æ¨¡å—
        self.gesture_recognizer = GestureRecognizer()
        self.gesture_visualizer = GestureVisualizer()
          # ç³»ç»ŸçŠ¶æ€
        self.is_running = False
        self.current_command = "none"
        self.last_command_time = 0
        self.display_mode = "full"  # full, pose_only, distance_only, gesture_only
        self.show_debug = True
        
        # æ€§èƒ½ç»Ÿè®¡
        self.frame_count = 0
        self.start_time = time.time()
        
        print("æ‰‹åŠ¿æ§åˆ¶ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        print("æ”¯æŒçš„æ‰‹åŠ¿:")
        print("  ğŸ™Œ èµ·é£: åŒæ‰‹é«˜ä¸¾è¿‡å¤´")
        print("  ğŸ‘‡ é™è½: åŒæ‰‹å‘ä¸‹å‹")
        print("  ğŸ‘‰ å‰è¿›: å³æ‰‹å‰æ¨")
        print("  ğŸ‘ˆ å·¦ç§»: å·¦æ‰‹æŒ‡å‘å·¦ä¾§")
        print("  ğŸ‘‰ å³ç§»: å³æ‰‹æŒ‡å‘å³ä¾§")
        print("  â˜ï¸ ä¸Šå‡: åŒæ‰‹å‘ä¸Šæ¨ä¸¾")
        print("  ğŸ‘‡ ä¸‹é™: åŒæ‰‹å‘ä¸‹å‹")
        print("  âœ‹ åœæ­¢: åŒæ‰‹èƒ¸å‰äº¤å‰")
    
    def start(self):
        """å¯åŠ¨ç³»ç»Ÿ"""
        print("å¯åŠ¨æ‘„åƒå¤´...")
        if not self.camera_capture.start():
            print("âŒ æ‘„åƒå¤´å¯åŠ¨å¤±è´¥")
            return False
        
        self.is_running = True
        print("âœ… ç³»ç»Ÿå¯åŠ¨æˆåŠŸ")
        return True
    
    def stop(self):
        """åœæ­¢ç³»ç»Ÿ"""
        self.is_running = False
        self.camera_capture.stop()
        self.image_visualizer.close_all()
        print("ç³»ç»Ÿå·²åœæ­¢")
    
    def process_frame(self):
        """å¤„ç†å•å¸§å›¾åƒ"""
        # 1. è·å–å›¾åƒ
        frame = self.camera_capture.get_frame()
        if frame is None:
            return None
        
        # 2. å›¾åƒé¢„å¤„ç†
        processed_frame = self.image_processor.preprocess(frame)
        
        # 3. å›¾åƒè´¨é‡è¯„ä¼°
        quality = self.quality_assessor.assess_quality(processed_frame)
        
        if not quality['valid']:
            # æ˜¾ç¤ºè´¨é‡è­¦å‘Š
            warning_frame = self._draw_quality_warning(processed_frame, quality)
            return warning_frame
        
        # 4. å§¿åŠ¿æ£€æµ‹
        pose_result = self.pose_detector.detect(processed_frame)
        
        if not pose_result.landmarks:
            # æ˜¾ç¤º"æœªæ£€æµ‹åˆ°äººä½“"
            no_person_frame = self._draw_no_person_warning(processed_frame)
            return no_person_frame
        
        # 5. è·ç¦»ä¼°ç®—
        distance_result = self.distance_estimator.estimate_distance(
            pose_result.landmarks,
            pose_result.frame_width,
            pose_result.frame_height
        )
        
        # 6. æ‰‹åŠ¿è¯†åˆ«
        frame_info = {
            'width': pose_result.frame_width,
            'height': pose_result.frame_height
        }
        gesture_result = self.gesture_recognizer.recognize(
            pose_result.landmarks, frame_info
        )
        
        # 7. å¤„ç†æ§åˆ¶æŒ‡ä»¤
        self._process_control_command(gesture_result, distance_result)
        
        # 8. å¯è§†åŒ–ç»“æœ
        output_frame = self._create_visualization(
            processed_frame, pose_result, distance_result, gesture_result, quality
        )
        
        return output_frame
    
    def _process_control_command(self, gesture_result, distance_result):
        """å¤„ç†æ§åˆ¶æŒ‡ä»¤"""
        current_time = time.time()
        
        # åªæœ‰é«˜ç½®ä¿¡åº¦çš„æ‰‹åŠ¿æ‰ä½œä¸ºæŒ‡ä»¤
        if gesture_result.confidence > 0.8 and gesture_result.gesture != "none":
            # é¿å…æŒ‡ä»¤é‡å¤è§¦å‘
            if (gesture_result.gesture != self.current_command or 
                current_time - self.last_command_time > 2.0):
                
                self.current_command = gesture_result.gesture
                self.last_command_time = current_time
                
                # æ‰§è¡ŒæŒ‡ä»¤å¤„ç†
                self._execute_command(gesture_result, distance_result)
    
    def _execute_command(self, gesture_result, distance_result):
        """æ‰§è¡Œæ§åˆ¶æŒ‡ä»¤"""
        gesture = gesture_result.gesture
        distance = distance_result.distance
        confidence = gesture_result.confidence
        
        print(f"\nğŸ¯ æ£€æµ‹åˆ°æŒ‡ä»¤: {gesture.upper()}")
        print(f"   ç½®ä¿¡åº¦: {confidence:.2f}")
        print(f"   è·ç¦»: {distance:.2f}m")
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„æ— äººæœºæ§åˆ¶ä»£ç 
        if gesture == "takeoff":
            print("   ğŸš æ‰§è¡Œèµ·é£æŒ‡ä»¤")
            # drone.takeoff()
        elif gesture == "landing":
            print("   ğŸ›¬ æ‰§è¡Œé™è½æŒ‡ä»¤")
            # drone.land()
        elif gesture == "forward":
            print("   â¬†ï¸ æ‰§è¡Œå‰è¿›æŒ‡ä»¤")
            # drone.move_forward(speed=self._calculate_speed(distance))
        elif gesture == "left":
            print("   â¬…ï¸ æ‰§è¡Œå·¦ç§»æŒ‡ä»¤")
            # drone.move_left(speed=self._calculate_speed(distance))
        elif gesture == "right":
            print("   â¡ï¸ æ‰§è¡Œå³ç§»æŒ‡ä»¤")
            # drone.move_right(speed=self._calculate_speed(distance))
        elif gesture == "up":
            print("   â¬†ï¸ æ‰§è¡Œä¸Šå‡æŒ‡ä»¤")
            # drone.move_up(speed=self._calculate_speed(distance))
        elif gesture == "down":
            print("   â¬‡ï¸ æ‰§è¡Œä¸‹é™æŒ‡ä»¤")
            # drone.move_down(speed=self._calculate_speed(distance))
        elif gesture == "stop":
            print("   â¹ï¸ æ‰§è¡Œåœæ­¢æŒ‡ä»¤")
            # drone.hover()
    
    def _calculate_speed(self, distance):
        """æ ¹æ®è·ç¦»è®¡ç®—æ§åˆ¶é€Ÿåº¦"""
        if distance < 2.0:
            return 0.3  # æ…¢é€Ÿ
        elif distance < 4.0:
            return 0.6  # ä¸­é€Ÿ
        else:
            return 1.0  # å¿«é€Ÿ
    
    def _create_visualization(self, frame, pose_result, distance_result, gesture_result, quality):
        """åˆ›å»ºç»¼åˆå¯è§†åŒ–"""
        output = frame.copy()
        
        # ç»˜åˆ¶å§¿åŠ¿
        if pose_result.landmarks:
            output = self.pose_visualizer.draw_pose(output, pose_result, draw_info=False)
        
        # ç»˜åˆ¶è·ç¦»ä¿¡æ¯
        output = self.distance_visualizer.draw_distance_info(
            output, distance_result, pose_result.landmarks, pose_result.bbox
        )
        
        # ç»˜åˆ¶æ‰‹åŠ¿ä¿¡æ¯
        output = self.gesture_visualizer.draw_gesture_info(
            output, gesture_result, pose_result.landmarks
        )
        
        # ç»˜åˆ¶ç³»ç»ŸçŠ¶æ€
        self._draw_system_status(output, quality)
        
        return output
    
    def _draw_system_status(self, image, quality):
        """ç»˜åˆ¶ç³»ç»ŸçŠ¶æ€ä¿¡æ¯"""
        # FPSä¿¡æ¯
        fps = self.camera_capture.get_fps()
        cv2.putText(image, f"FPS: {fps:.1f}", (image.shape[1] - 120, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        
        # å›¾åƒè´¨é‡
        quality_color = (0, 255, 0) if quality['valid'] else (0, 0, 255)
        cv2.putText(image, f"Quality: {quality['quality']}", (image.shape[1] - 150, 60),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, quality_color, 1)
        
        # å½“å‰æŒ‡ä»¤
        if self.current_command != "none":
            cv2.putText(image, f"Last CMD: {self.current_command.upper()}", 
                       (image.shape[1] - 200, 90),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)
    
    def _draw_quality_warning(self, frame, quality):
        """ç»˜åˆ¶å›¾åƒè´¨é‡è­¦å‘Š"""
        output = frame.copy()
        warning_text = f"å›¾åƒè´¨é‡å·®: {quality['reason']}"
        
        # æ·»åŠ åŠé€æ˜èƒŒæ™¯
        overlay = output.copy()
        cv2.rectangle(overlay, (10, 10), (400, 80), (0, 0, 255), -1)
        cv2.addWeighted(overlay, 0.7, output, 0.3, 0, output)
        
        cv2.putText(output, warning_text, (20, 50),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        return output
    
    def _draw_no_person_warning(self, frame):
        """ç»˜åˆ¶æœªæ£€æµ‹åˆ°äººä½“è­¦å‘Š"""
        output = frame.copy()
        warning_text = "æœªæ£€æµ‹åˆ°äººä½“"
        
        # æ·»åŠ åŠé€æ˜èƒŒæ™¯
        overlay = output.copy()
        cv2.rectangle(overlay, (10, 10), (300, 80), (0, 165, 255), -1)
        cv2.addWeighted(overlay, 0.7, output, 0.3, 0, output)
        
        cv2.putText(output, warning_text, (20, 50),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        
        return output
    
    def get_system_statistics(self):
        """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        pose_stats = self.pose_detector.get_statistics()
        distance_stats = self.distance_estimator.get_statistics()
        gesture_stats = self.gesture_recognizer.get_statistics()
        
        return {
            "pose_detection": pose_stats,
            "distance_estimation": distance_stats,
            "gesture_recognition": gesture_stats,
            "camera_fps": self.camera_capture.get_fps()
        }

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 50)
    print("  æ‰‹åŠ¿æ§åˆ¶ç³»ç»Ÿ - ç»¼åˆæ¼”ç¤º")
    print("=" * 50)
    print("æ”¯æŒçš„æ‰‹åŠ¿:")
    print("  ğŸ™Œ èµ·é£: åŒæ‰‹é«˜ä¸¾è¿‡å¤´")
    print("  ğŸ‘‡ é™è½: åŒæ‰‹å‘ä¸‹å‹")
    print("  ğŸ‘‰ æ–¹å‘: æ‰‹æŒ‡æŒ‡å‘ç§»åŠ¨æ–¹å‘")
    print("  âœ‹ åœæ­¢: åŒæ‰‹èƒ¸å‰äº¤å‰")
    print("  ğŸ“Š ç»Ÿè®¡: æŒ‰ 's' æŸ¥çœ‹ç³»ç»Ÿç»Ÿè®¡")
    print("  ğŸšª é€€å‡º: æŒ‰ 'q' é€€å‡ºç¨‹åº")
    print("=" * 50)
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    system = GestureControlSystem(camera_id=0)
    
    if not system.start():
        return
    
    try:
        print("ç³»ç»Ÿè¿è¡Œä¸­ï¼Œå¼€å§‹æ‰‹åŠ¿æ§åˆ¶...")
        
        while system.is_running:
            # å¤„ç†å¸§
            output_frame = system.process_frame()
            
            if output_frame is not None:
                # æ˜¾ç¤ºç»“æœ
                key = system.image_visualizer.show_image(output_frame, "æ‰‹åŠ¿æ§åˆ¶ç³»ç»Ÿ")
                
                if key == ord('q'):
                    break
                elif key == ord('s'):
                    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                    stats = system.get_system_statistics()
                    print("\n" + "=" * 30)
                    print("ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯:")
                    print("=" * 30)
                    
                    print(f"æ‘„åƒå¤´FPS: {stats['camera_fps']:.1f}")
                    print(f"å§¿åŠ¿æ£€æµ‹æˆåŠŸç‡: {stats['pose_detection']['success_rate']:.1f}%")
                    print(f"è·ç¦»ä¼°ç®—æˆåŠŸç‡: {stats['distance_estimation']['success_rate']:.1f}%")
                    print(f"æ‰‹åŠ¿è¯†åˆ«æˆåŠŸç‡: {stats['gesture_recognition']['success_rate']:.1f}%")
                    print(f"å½“å‰æ‰‹åŠ¿: {stats['gesture_recognition']['current_gesture']}")
                    print("=" * 30)
                elif key == ord('r'):
                    # é‡ç½®ç»Ÿè®¡
                    system.gesture_recognizer.reset_statistics()
                    print("ç»Ÿè®¡ä¿¡æ¯å·²é‡ç½®")
            else:
                time.sleep(0.01)
    
    except KeyboardInterrupt:
        print("\næ”¶åˆ°ä¸­æ–­ä¿¡å·")
    except Exception as e:
        print(f"ç³»ç»Ÿé”™è¯¯: {e}")
    finally:
        system.stop()
        print("ç³»ç»Ÿå·²å®‰å…¨é€€å‡º")

if __name__ == "__main__":
    main()
