"""
é«˜çº§é›†æˆæ¼”ç¤º - å±•ç¤ºæ¨¡å—çš„é«˜çº§ç”¨æ³•å’Œæ€§èƒ½ä¼˜åŒ–
"""

import cv2
import time
import numpy as np
import sys
import os
import threading
import queue
from dataclasses import dataclass
from typing import Optional, Dict, Any
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# æ·»åŠ æ¨¡å—è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'modules'))

try:
    from image_processing.image_processor import CameraCapture, ImageProcessor, ImageQualityAssessment, ImageVisualizer
    from pose_detection.pose_detector import PoseDetector, PoseVisualizer, PoseAnalyzer
    from distance_estimation.distance_estimator import DistanceEstimator, DistanceVisualizer
    from gesture_recognition.gesture_recognizer import GestureRecognizer, GestureVisualizer
except ImportError as e:
    print(f"æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿æ‰€æœ‰æ¨¡å—éƒ½åœ¨æ­£ç¡®çš„ä½ç½®")
    sys.exit(1)

@dataclass
class FrameData:
    """å¸§æ•°æ®ç»“æ„"""
    frame: np.ndarray
    timestamp: float
    frame_id: int

@dataclass
class ProcessingResult:
    """å¤„ç†ç»“æœç»“æ„"""
    frame_data: FrameData
    pose_result: Any
    distance_result: Any
    gesture_result: Any
    quality_result: Any

class AdvancedGestureSystem:
    """é«˜çº§æ‰‹åŠ¿æ§åˆ¶ç³»ç»Ÿ - æ”¯æŒå¤šçº¿ç¨‹å’Œæ€§èƒ½ä¼˜åŒ–"""
    
    def __init__(self, config: Optional[Dict] = None):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        self.config = config or self._get_default_config()
        
        # åˆå§‹åŒ–æ¨¡å—
        self._init_modules()
        
        # å¤šçº¿ç¨‹ç»„ä»¶
        self.frame_queue = queue.Queue(maxsize=10)
        self.result_queue = queue.Queue(maxsize=10)
        self.processing_thread = None
        self.visualization_thread = None
        
        # ç³»ç»ŸçŠ¶æ€
        self.is_running = False
        self.frame_counter = 0
        self.performance_stats = {
            'fps': 0.0,
            'processing_time': 0.0,
            'detection_success_rate': 0.0
        }
        
        print("é«˜çº§æ‰‹åŠ¿æ§åˆ¶ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def _get_default_config(self) -> Dict:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            'camera': {
                'id': 0,
                'width': 640,
                'height': 480,
                'fps': 30
            },
            'pose_detection': {
                'model_complexity': 1,
                'min_detection_confidence': 0.5,
                'min_tracking_confidence': 0.5
            },
            'distance_estimation': {
                'use_kalman_filter': True,
                'shoulder_width_cm': 40.0
            },
            'gesture_recognition': {
                'confidence_threshold': 0.8,
                'temporal_smoothing': True
            },
            'performance': {
                'max_fps': 30,
                'enable_threading': True,
                'profiling': False
            }
        }
    
    def _init_modules(self):
        """åˆå§‹åŒ–æ‰€æœ‰æ¨¡å—"""
        # å›¾åƒå¤„ç†æ¨¡å—
        self.camera_capture = CameraCapture(
            camera_id=self.config['camera']['id'],
            width=self.config['camera']['width'],
            height=self.config['camera']['height']
        )
        self.image_processor = ImageProcessor()
        self.quality_assessor = ImageQualityAssessment()
        self.image_visualizer = ImageVisualizer()
        
        # å§¿åŠ¿æ£€æµ‹æ¨¡å—
        self.pose_detector = PoseDetector(
            model_complexity=self.config['pose_detection']['model_complexity']
        )
        self.pose_visualizer = PoseVisualizer()
        self.pose_analyzer = PoseAnalyzer()
        
        # è·ç¦»ä¼°ç®—æ¨¡å—
        self.distance_estimator = DistanceEstimator()
        
        # æ‰‹åŠ¿è¯†åˆ«æ¨¡å—
        self.gesture_recognizer = GestureRecognizer()
        
        # å¯è§†åŒ–å™¨
        self.distance_visualizer = DistanceVisualizer()
        self.gesture_visualizer = GestureVisualizer()
    
    def start(self) -> bool:
        """å¯åŠ¨ç³»ç»Ÿ"""
        print("å¯åŠ¨é«˜çº§æ‰‹åŠ¿æ§åˆ¶ç³»ç»Ÿ...")
        
        # å¯åŠ¨æ‘„åƒå¤´
        if not self.camera_capture.start():
            print("âŒ æ‘„åƒå¤´å¯åŠ¨å¤±è´¥")
            return False
        
        self.is_running = True
        
        if self.config['performance']['enable_threading']:
            # å¯åŠ¨å¤šçº¿ç¨‹å¤„ç†
            self.processing_thread = threading.Thread(target=self._processing_loop, daemon=True)
            self.visualization_thread = threading.Thread(target=self._visualization_loop, daemon=True)
            
            self.processing_thread.start()
            self.visualization_thread.start()
        
        print("âœ… ç³»ç»Ÿå¯åŠ¨æˆåŠŸ")
        return True
    
    def stop(self):
        """åœæ­¢ç³»ç»Ÿ"""
        self.is_running = False
        
        if self.processing_thread:
            self.processing_thread.join(timeout=1.0)
        if self.visualization_thread:
            self.visualization_thread.join(timeout=1.0)
        
        self.camera_capture.stop()
        self.image_visualizer.close_all()
        print("ç³»ç»Ÿå·²åœæ­¢")
    
    def run_single_threaded(self):
        """å•çº¿ç¨‹è¿è¡Œæ¨¡å¼"""
        print("è¿è¡Œå•çº¿ç¨‹æ¨¡å¼...")
        
        try:
            while self.is_running:
                # æ•è·å¸§
                frame = self.camera_capture.get_frame()
                if frame is None:
                    time.sleep(0.01)
                    continue
                
                frame_data = FrameData(
                    frame=frame,
                    timestamp=time.time(),
                    frame_id=self.frame_counter
                )
                self.frame_counter += 1
                
                # å¤„ç†å¸§
                result = self._process_frame_data(frame_data)
                
                # æ˜¾ç¤ºç»“æœ
                if result:
                    visualization = self._create_advanced_visualization(result)
                    key = self.image_visualizer.show_image(visualization, "Advanced Gesture System")
                    
                    if key == ord('q'):
                        break
                    elif key == ord('s'):
                        self._print_performance_stats()
                    elif key == ord('r'):
                        self._reset_performance_stats()
                        
        except KeyboardInterrupt:
            print("\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        finally:
            self.stop()
    
    def run_multi_threaded(self):
        """å¤šçº¿ç¨‹è¿è¡Œæ¨¡å¼"""
        print("è¿è¡Œå¤šçº¿ç¨‹æ¨¡å¼...")
        
        try:
            # ä¸»çº¿ç¨‹è´Ÿè´£æ•è·å¸§
            while self.is_running:
                frame = self.camera_capture.get_frame()
                if frame is None:
                    time.sleep(0.01)
                    continue
                
                frame_data = FrameData(
                    frame=frame,
                    timestamp=time.time(),
                    frame_id=self.frame_counter
                )
                self.frame_counter += 1
                
                # å°†å¸§æ”¾å…¥å¤„ç†é˜Ÿåˆ—
                try:
                    self.frame_queue.put_nowait(frame_data)
                except queue.Full:
                    # ä¸¢å¼ƒæœ€æ—§çš„å¸§
                    try:
                        self.frame_queue.get_nowait()
                        self.frame_queue.put_nowait(frame_data)
                    except queue.Empty:
                        pass
                
        except KeyboardInterrupt:
            print("\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        finally:
            self.stop()
    
    def _processing_loop(self):
        """å¤„ç†å¾ªç¯çº¿ç¨‹"""
        while self.is_running:
            try:
                # è·å–å¸§æ•°æ®
                frame_data = self.frame_queue.get(timeout=0.1)
                
                # å¤„ç†å¸§
                result = self._process_frame_data(frame_data)
                
                if result:
                    # å°†ç»“æœæ”¾å…¥æ˜¾ç¤ºé˜Ÿåˆ—
                    try:
                        self.result_queue.put_nowait(result)
                    except queue.Full:
                        # ä¸¢å¼ƒæœ€æ—§çš„ç»“æœ
                        try:
                            self.result_queue.get_nowait()
                            self.result_queue.put_nowait(result)
                        except queue.Empty:
                            pass
                
            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"å¤„ç†å¾ªç¯é”™è¯¯: {e}")
    
    def _visualization_loop(self):
        """å¯è§†åŒ–å¾ªç¯çº¿ç¨‹"""
        while self.is_running:
            try:
                # è·å–å¤„ç†ç»“æœ
                result = self.result_queue.get(timeout=0.1)
                
                # åˆ›å»ºå¯è§†åŒ–
                visualization = self._create_advanced_visualization(result)
                
                # æ˜¾ç¤ºç»“æœ
                key = self.image_visualizer.show_image(visualization, "Advanced Gesture System")
                
                if key == ord('q'):
                    self.is_running = False
                    break
                elif key == ord('s'):
                    self._print_performance_stats()
                elif key == ord('r'):
                    self._reset_performance_stats()
                
            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"å¯è§†åŒ–å¾ªç¯é”™è¯¯: {e}")
    
    def _process_frame_data(self, frame_data: FrameData) -> Optional[ProcessingResult]:
        """å¤„ç†å¸§æ•°æ®"""
        start_time = time.time()
        
        try:
            # å›¾åƒé¢„å¤„ç†
            processed_frame = self.image_processor.preprocess(frame_data.frame)
            
            # å›¾åƒè´¨é‡è¯„ä¼°
            quality_result = self.quality_assessor.assess_quality(processed_frame)
            
            if not quality_result['valid']:
                return ProcessingResult(
                    frame_data=frame_data,
                    pose_result=None,
                    distance_result=None,
                    gesture_result=None,
                    quality_result=quality_result
                )
            
            # å§¿åŠ¿æ£€æµ‹
            pose_result = self.pose_detector.detect(processed_frame)
            
            if not pose_result.landmarks:
                return ProcessingResult(
                    frame_data=frame_data,
                    pose_result=pose_result,
                    distance_result=None,
                    gesture_result=None,
                    quality_result=quality_result
                )
            
            # è·ç¦»ä¼°ç®—
            distance_result = self.distance_estimator.estimate_distance(
                pose_result.landmarks,
                pose_result.frame_width,
                pose_result.frame_height
            )
            
            # æ‰‹åŠ¿è¯†åˆ«
            frame_info = {
                'width': pose_result.frame_width,
                'height': pose_result.frame_height
            }
            gesture_result = self.gesture_recognizer.recognize(
                pose_result.landmarks, frame_info
            )
            
            # æ›´æ–°æ€§èƒ½ç»Ÿè®¡
            processing_time = time.time() - start_time
            self._update_performance_stats(processing_time)
            
            return ProcessingResult(
                frame_data=frame_data,
                pose_result=pose_result,
                distance_result=distance_result,
                gesture_result=gesture_result,
                quality_result=quality_result
            )
            
        except Exception as e:
            logger.error(f"å¸§å¤„ç†é”™è¯¯: {e}")
            return None
    
    def _create_advanced_visualization(self, result: ProcessingResult) -> np.ndarray:
        """åˆ›å»ºé«˜çº§å¯è§†åŒ–"""
        output = result.frame_data.frame.copy()
        
        # ç»˜åˆ¶è´¨é‡è­¦å‘Š
        if not result.quality_result['valid']:
            return self._draw_quality_warning(output, result.quality_result)
        
        # ç»˜åˆ¶æ— äººä½“è­¦å‘Š
        if not result.pose_result or not result.pose_result.landmarks:
            return self._draw_no_person_warning(output)
        
        # ç»˜åˆ¶å§¿åŠ¿
        if result.pose_result.landmarks:
            output = self.pose_visualizer.draw_pose(output, result.pose_result, draw_info=False)
        
        # ç»˜åˆ¶è·ç¦»ä¿¡æ¯
        if result.distance_result:
            output = self.distance_visualizer.draw_distance_info(
                output, result.distance_result, result.pose_result.landmarks, result.pose_result.bbox
            )
        
        # ç»˜åˆ¶æ‰‹åŠ¿ä¿¡æ¯
        if result.gesture_result:
            output = self.gesture_visualizer.draw_gesture_info(
                output, result.gesture_result, result.pose_result.landmarks
            )
        
        # ç»˜åˆ¶é«˜çº§çŠ¶æ€ä¿¡æ¯
        self._draw_advanced_status(output, result)
        
        return output
    
    def _draw_advanced_status(self, image: np.ndarray, result: ProcessingResult):
        """ç»˜åˆ¶é«˜çº§çŠ¶æ€ä¿¡æ¯"""
        # æ€§èƒ½ä¿¡æ¯
        fps = self.performance_stats['fps']
        processing_time = self.performance_stats['processing_time']
        
        # ç³»ç»Ÿä¿¡æ¯é¢æ¿
        panel_height = 120
        panel = np.zeros((panel_height, image.shape[1], 3), dtype=np.uint8)
        panel[:, :] = (40, 40, 40)  # æ·±ç°è‰²èƒŒæ™¯
        
        # ç»˜åˆ¶æ€§èƒ½ä¿¡æ¯
        text_color = (255, 255, 255)
        cv2.putText(panel, f"FPS: {fps:.1f}", (10, 25),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2)
        
        cv2.putText(panel, f"Processing: {processing_time*1000:.1f}ms", (10, 50),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2)
        
        cv2.putText(panel, f"Frame ID: {result.frame_data.frame_id}", (10, 75),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2)
        
        # ç³»ç»ŸçŠ¶æ€
        status_color = (0, 255, 0) if result.quality_result['valid'] else (0, 0, 255)
        cv2.putText(panel, f"Status: {'Running' if result.quality_result['valid'] else 'Warning'}", 
                   (250, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, status_color, 2)
        
        # æ£€æµ‹çŠ¶æ€
        pose_status = "âœ“" if result.pose_result and result.pose_result.landmarks else "âœ—"
        distance_status = "âœ“" if result.distance_result else "âœ—"
        gesture_status = "âœ“" if result.gesture_result and result.gesture_result.gesture != "none" else "âœ—"
        
        cv2.putText(panel, f"Pose: {pose_status}  Distance: {distance_status}  Gesture: {gesture_status}", 
                   (250, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, text_color, 1)
        
        # æ§åˆ¶æç¤º
        cv2.putText(panel, "Press 'q' to quit, 's' for stats, 'r' to reset", 
                   (250, 75), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (150, 150, 150), 1)
        
        # å°†é¢æ¿æ·»åŠ åˆ°å›¾åƒåº•éƒ¨
        output_with_panel = np.vstack([image, panel])
        
        # æ›´æ–°åŸå›¾åƒ
        image[:] = output_with_panel[:image.shape[0], :]
    
    def _draw_quality_warning(self, frame: np.ndarray, quality_result: Dict) -> np.ndarray:
        """ç»˜åˆ¶è´¨é‡è­¦å‘Š"""
        output = frame.copy()
        warning_text = f"å›¾åƒè´¨é‡å·®: {quality_result['reason']}"
        
        overlay = output.copy()
        cv2.rectangle(overlay, (10, 10), (500, 80), (0, 0, 255), -1)
        cv2.addWeighted(overlay, 0.7, output, 0.3, 0, output)
        
        cv2.putText(output, warning_text, (20, 50),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        
        return output
    
    def _draw_no_person_warning(self, frame: np.ndarray) -> np.ndarray:
        """ç»˜åˆ¶æ— äººä½“è­¦å‘Š"""
        output = frame.copy()
        warning_text = "æœªæ£€æµ‹åˆ°äººä½“"
        
        overlay = output.copy()
        cv2.rectangle(overlay, (10, 10), (350, 80), (0, 165, 255), -1)
        cv2.addWeighted(overlay, 0.7, output, 0.3, 0, output)
        
        cv2.putText(output, warning_text, (20, 50),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)
        
        return output
    
    def _update_performance_stats(self, processing_time: float):
        """æ›´æ–°æ€§èƒ½ç»Ÿè®¡"""
        self.performance_stats['processing_time'] = processing_time
        
        # è®¡ç®—FPSï¼ˆç®€å•ç§»åŠ¨å¹³å‡ï¼‰
        current_fps = 1.0 / processing_time if processing_time > 0 else 0
        alpha = 0.1  # å¹³æ»‘å› å­
        self.performance_stats['fps'] = (
            alpha * current_fps + (1 - alpha) * self.performance_stats['fps']
        )
    
    def _print_performance_stats(self):
        """æ‰“å°æ€§èƒ½ç»Ÿè®¡"""
        print("\n" + "=" * 60)
        print("  é«˜çº§ç³»ç»Ÿæ€§èƒ½ç»Ÿè®¡")
        print("=" * 60)
        print(f"å½“å‰FPS: {self.performance_stats['fps']:.2f}")
        print(f"å¤„ç†æ—¶é—´: {self.performance_stats['processing_time']*1000:.2f}ms")
        print(f"æ€»å¤„ç†å¸§æ•°: {self.frame_counter}")
        print(f"é˜Ÿåˆ—çŠ¶æ€: Frame={self.frame_queue.qsize()}, Result={self.result_queue.qsize()}")
        print(f"å¤šçº¿ç¨‹æ¨¡å¼: {'å¯ç”¨' if self.config['performance']['enable_threading'] else 'ç¦ç”¨'}")
        print("=" * 60)
    
    def _reset_performance_stats(self):
        """é‡ç½®æ€§èƒ½ç»Ÿè®¡"""
        self.performance_stats = {
            'fps': 0.0,
            'processing_time': 0.0,
            'detection_success_rate': 0.0
        }
        self.frame_counter = 0
        print("æ€§èƒ½ç»Ÿè®¡å·²é‡ç½®")
    
    def run(self):
        """è¿è¡Œç³»ç»Ÿ"""
        if not self.start():
            return
        
        if self.config['performance']['enable_threading']:
            self.run_multi_threaded()
        else:
            self.run_single_threaded()

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("  é«˜çº§æ‰‹åŠ¿æ§åˆ¶ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 70)
    print("ç‰¹æ€§:")
    print("  ğŸš€ å¤šçº¿ç¨‹å¤„ç†æ¶æ„")
    print("  ğŸ“Š å®æ—¶æ€§èƒ½ç›‘æ§")
    print("  ğŸ¨ é«˜çº§å¯è§†åŒ–ç•Œé¢")
    print("  âš™ï¸ å¯é…ç½®å‚æ•°")
    print("  ğŸ”§ é”™è¯¯å¤„ç†å’Œæ¢å¤")
    print("  ğŸ“ˆ è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯")
    print("=" * 70)
    
    # é«˜çº§é…ç½®
    config = {
        'camera': {
            'id': 0,
            'width': 640,
            'height': 480,
            'fps': 30
        },
        'pose_detection': {
            'model_complexity': 1,
            'min_detection_confidence': 0.5,
            'min_tracking_confidence': 0.5
        },
        'distance_estimation': {
            'use_kalman_filter': True,
            'shoulder_width_cm': 40.0
        },
        'gesture_recognition': {
            'confidence_threshold': 0.8,
            'temporal_smoothing': True
        },
        'performance': {
            'max_fps': 30,
            'enable_threading': True,
            'profiling': True
        }
    }
    
    try:
        system = AdvancedGestureSystem(config)
        system.run()
    except Exception as e:
        print(f"ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {e}")
        logger.exception(e)

if __name__ == "__main__":
    main()
