"""
æ‰‹åŠ¿è¯†åˆ«æ§åˆ¶ç³»ç»Ÿä¸»å…¥å£ - å·²ä¿®æ”¹ä¸ºå›¾ç‰‡é›†æ‰¹å¤„ç†æ¨¡å¼

åŠŸèƒ½ï¼šéå†æŒ‡å®šæ–‡ä»¶å¤¹ä¸‹çš„å›¾ç‰‡ï¼Œå¯¹æ¯å¼ å›¾ç‰‡è¿›è¡Œéª¨éª¼ç‚¹æ£€æµ‹ã€è·ç¦»ä¼°ç®—å’Œæ‰‹åŠ¿è¯†åˆ«ã€‚
"""

import cv2
import time
import numpy as np
import sys
import os
import logging
import argparse
import threading
import queue
from typing import Optional, Dict, Any

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# --- æ¨¡å—è·¯å¾„æ·»åŠ  (ä¿æŒä¸å˜) ---
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'modules'))
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'code_ws'))

try:
    # å‡è®¾è¿™äº›æ¨¡å—å·²å­˜åœ¨ä¸”èƒ½è¢«å¯¼å…¥
    from image_processing.image_processor import ImageProcessor, ImageQualityAssessment, ImageVisualizer
    from pose_detection.pose_detector import PoseDetector, PoseVisualizer, PoseAnalyzer
    from distance_estimation.distance_estimator import DistanceEstimator, DistanceVisualizer
    from gesture_recognition.gesture_recognizer import GestureRecognizer, GestureVisualizer
    
    # å‡è®¾ CameraCapture å·²ç»ä¸å†éœ€è¦å¯¼å…¥
    
except ImportError as e:
    logger.error(f"æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print(f"æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿æ‰€æœ‰æ¨¡å—éƒ½åœ¨æ­£ç¡®çš„ä½ç½®")
    sys.exit(1)


# =================================================================
# ã€æ–°å¢/æ›¿æ¢æ¨¡å—ã€‘ï¼šImageSetCapture - ç”¨äºè¯»å–å›¾ç‰‡é›† (ä¿æŒä¸å˜)
# =================================================================

class ImageSetCapture:
    """
    å›¾ç‰‡é›†æ•è·å™¨ï¼šç”¨äºè¯»å–æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶ï¼Œæ›¿ä»£CameraCapture
    """

    def __init__(self, folder_path: str, width: int, height: int, supported_exts: tuple = ('.jpg', '.jpeg', '.png', '.bmp')):
        self.folder_path = folder_path
        self.supported_exts = supported_exts
        self.width = width
        self.height = height
        self.image_files = self._get_image_files()
        self.current_index = 0
        self.num_frames = len(self.image_files)
        self.last_frame_time = time.time()
        self.last_fps = 0.0
        logger.info(f"å›¾ç‰‡é›†åŠ è½½å®Œæˆï¼Œå…±æ‰¾åˆ° {self.num_frames} å¼ å›¾ç‰‡ã€‚")

    def _get_image_files(self):
        """æ‰«ææ–‡ä»¶å¤¹ï¼Œè·å–æ‰€æœ‰æ”¯æŒçš„å›¾ç‰‡è·¯å¾„å¹¶æŒ‰åç§°æ’åº"""
        if not os.path.isdir(self.folder_path):
            logger.error(f"å›¾ç‰‡æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {self.folder_path}")
            return []
        
        # æŒ‰æ–‡ä»¶åæ’åºï¼Œç¡®ä¿å¤„ç†é¡ºåºä¸€è‡´
        files = []
        for f in sorted(os.listdir(self.folder_path)):
            if f.lower().endswith(self.supported_exts):
                files.append(os.path.join(self.folder_path, f))
        
        return files

    def start(self):
        """å¼€å§‹è¯»å– - æ£€æŸ¥æ–‡ä»¶æ•°é‡"""
        if not self.image_files:
            logger.error("åœ¨æŒ‡å®šæ–‡ä»¶å¤¹ä¸­æœªæ‰¾åˆ°ä»»ä½•å›¾ç‰‡ã€‚")
            return False
        self.current_index = 0
        self.last_frame_time = time.time()
        print(f"âœ… å¼€å§‹å¤„ç†å›¾ç‰‡é›†: {self.folder_path}ï¼Œæ€»è®¡ {self.num_frames} å¼ å›¾ç‰‡ã€‚")
        return True

    def get_frame(self) -> Optional[np.ndarray]:
        """
        è¯»å–ä¸‹ä¸€å¼ å›¾ç‰‡ä½œä¸ºä¸€å¸§
        :return: OpenCVæ ¼å¼çš„å›¾åƒ (BGR) æˆ– None (è¡¨ç¤ºå¤„ç†å®Œæ¯•)
        """
        if self.current_index >= self.num_frames:
            # è¾¾åˆ°å›¾ç‰‡é›†æœ«å°¾ï¼Œåœæ­¢
            return None

        # è®¡ç®—æ¨¡æ‹Ÿçš„FPS
        current_time = time.time()
        if self.current_index > 0:
            self.last_fps = 1.0 / (current_time - self.last_frame_time)
        self.last_frame_time = current_time

        # è¯»å–å›¾ç‰‡
        image_path = self.image_files[self.current_index]
        print(f"ğŸ–¼ï¸ æ­£åœ¨å¤„ç† [{self.current_index + 1}/{self.num_frames}]: {os.path.basename(image_path)}")
        frame = cv2.imread(image_path)
        
        # ã€é‡è¦ã€‘ï¼šå¦‚æœå›¾ç‰‡å¤§å°ä¸ä¸€è‡´ï¼Œresizeåˆ°ç›®æ ‡å°ºå¯¸
        if frame is not None and (frame.shape[1] != self.width or frame.shape[0] != self.height):
            frame = cv2.resize(frame, (self.width, self.height))

        # å¢åŠ ç´¢å¼•
        self.current_index += 1
        
        return frame

    def get_fps(self) -> float:
        """è¿”å›å½“å‰å¤„ç†é€Ÿåº¦ï¼ˆæ¨¡æ‹ŸFPSï¼‰"""
        return self.last_fps

    def stop(self):
        """åœæ­¢è¯»å–ï¼ˆé‡ç½®ç´¢å¼•ï¼‰"""
        self.current_index = 0
        pass

# =================================================================
# ã€æ ¸å¿ƒä¿®æ”¹ã€‘ï¼šGestureControlSystem
# =================================================================

class GestureControlSystem:
    """æ‰‹åŠ¿æ§åˆ¶ç³»ç»Ÿ - é›†æˆæ‰€æœ‰æ¨¡å—"""
    
    # ã€ä¿®æ”¹ç‚¹ 1ã€‘ï¼šæ¥æ”¶ folder_path ä»£æ›¿ camera_id
    def __init__(self, folder_path: str, width=640, height=480):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        print("åˆå§‹åŒ–æ‰‹åŠ¿æ§åˆ¶ç³»ç»Ÿ (å›¾ç‰‡é›†æ¨¡å¼)...")
        
        self.folder_path = folder_path
        self.width = width
        self.height = height
        
        try:
            # å›¾åƒå¤„ç†æ¨¡å—
            # ã€ä¿®æ”¹ç‚¹ 2ã€‘ï¼šä½¿ç”¨ ImageSetCapture æ›¿æ¢ CameraCapture
            self.camera_capture = ImageSetCapture(folder_path=folder_path, width=width, height=height)
            self.image_processor = ImageProcessor()
            self.quality_assessor = ImageQualityAssessment()
            self.image_visualizer = ImageVisualizer() 
            
            # å§¿åŠ¿æ£€æµ‹æ¨¡å—
            self.pose_detector = PoseDetector(model_complexity=1)
            self.pose_visualizer = PoseVisualizer()
            self.pose_analyzer = PoseAnalyzer()
            
            # è·ç¦»ä¼°ç®—æ¨¡å—
            self.distance_estimator = DistanceEstimator()
            self.distance_visualizer = DistanceVisualizer()
            
            # æ‰‹åŠ¿è¯†åˆ«æ¨¡å—
            self.gesture_recognizer = GestureRecognizer()
            self.gesture_visualizer = GestureVisualizer()
            
        except Exception as e:
            logger.error(f"ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            print(f"âŒ ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            print("è¯·ç¡®ä¿æ‰€æœ‰ä¾èµ–åŒ…å·²å®‰è£…")
            raise
            
        # ç³»ç»ŸçŠ¶æ€
        self.is_running = False
        self.current_command = "none"
        self.last_command_time = 0
        self.display_mode = "full"  # full, pose_only, distance_only, gesture_only
        self.show_debug = True
        
        # æ€§èƒ½ç»Ÿè®¡
        self.frame_count = 0
        self.start_time = time.time()
        
        print("æ‰‹åŠ¿æ§åˆ¶ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        self._print_supported_gestures()

    def _print_supported_gestures(self):
        """æ‰“å°æ”¯æŒçš„æ‰‹åŠ¿ (ä»åŸå§‹ä»£ç å¤åˆ¶è¿‡æ¥)"""
        print("æ”¯æŒçš„æ‰‹åŠ¿:")
        print("  ğŸ™Œ èµ·é£: åŒæ‰‹é«˜ä¸¾è¿‡å¤´")
        print("  ğŸ‘‡ é™è½: åŒæ‰‹å‘ä¸‹å‹")
        print("  ğŸ‘‰ å‰è¿›: å³æ‰‹å‰æ¨")
        print("  ğŸ‘ˆ å·¦ç§»: å·¦æ‰‹æŒ‡å‘å·¦ä¾§")
        print("  ğŸ‘‰ å³ç§»: å³æ‰‹æŒ‡å‘å³ä¾§")
        print("  â˜ï¸ ä¸Šå‡: åŒæ‰‹å‘ä¸Šæ¨ä¸¾")
        print("  ğŸ‘‡ ä¸‹é™: åŒæ‰‹å‘ä¸‹å‹")
        print("  âœ‹ åœæ­¢: åŒæ‰‹èƒ¸å‰äº¤å‰")
    
    # =======================================================
    # ã€æ ¸å¿ƒä¿®æ”¹åŒºï¼šä¿®å¤ 'GestureResult' object has no attribute 'get'ã€‘
    # =======================================================
    def _process_control_command(self, gesture_result: Any, distance_result: Dict[str, Any]):
        """
        å¤„ç†æ‰‹åŠ¿è¯†åˆ«ç»“æœï¼Œç¡®å®šæ§åˆ¶æŒ‡ä»¤
        ã€ä¿®å¤ï¼šä½¿ç”¨ getattr å…¼å®¹ GestureResult å¯¹è±¡ã€‘
        """
        current_time = time.time()
        
        # 1. å°è¯•ä» GestureResult å¯¹è±¡ä¸­è·å– 'gesture' å±æ€§ (æ¨è)
        command_name = getattr(gesture_result, 'gesture', None) 
        
        if command_name is None:
            # 2. å¦‚æœä¸æ˜¯å¯¹è±¡æˆ–æ²¡æœ‰ 'gesture' å±æ€§ï¼Œåˆ™å°è¯•ä»å­—å…¸ä¸­è·å– 'command' é”® (å…¼å®¹æ—§æ¥å£)
            command_name = gesture_result.get('command', None) 
        
        # æ£€æŸ¥æ˜¯å¦è¯†åˆ«åˆ°äº†æœ‰æ•ˆæ‰‹åŠ¿
        if command_name and command_name != "none":
            self.current_command = command_name
            self.last_command_time = current_time
            # ã€æ­¤å¤„æ˜¯æ‰§è¡ŒæŒ‡ä»¤çš„æ ¸å¿ƒé€»è¾‘ï¼Œåœ¨å›¾ç‰‡é›†æ¨¡å¼ä¸‹ï¼Œæˆ‘ä»¬åªæ‰“å°ã€‘
            self._execute_command(self.current_command)
            return

        # è·ç¦»å’Œå§¿åŠ¿ç›¸å…³æŒ‡ä»¤ (å¦‚æœéœ€è¦)
        # ç¤ºä¾‹ï¼šå¦‚æœè·ç¦»å¤ªè¿‘ï¼Œå¼ºåˆ¶åœæ­¢
        if distance_result.get('distance_cm', 999) < 50:
             if current_time - self.last_command_time > 2: # é¿å…é¢‘ç¹è§¦å‘
                 self.current_command = "forced_stop (too close)"
                 self.last_command_time = current_time
                 self._execute_command(self.current_command)
                 return

        # å¦‚æœé•¿æ—¶é—´æ²¡æœ‰æ–°çš„æœ‰æ•ˆæŒ‡ä»¤ï¼Œå‘½ä»¤æ¢å¤ä¸º none
        if current_time - self.last_command_time > 1.0: # 1ç§’ä¸æ‰§è¡Œä»»ä½•æŒ‡ä»¤
            self.current_command = "none"

    def _create_visualization(self, processed_frame, pose_result, distance_result, gesture_result, quality):
        """ç»¼åˆæ‰€æœ‰æ¨¡å—çš„å¯è§†åŒ–ç»“æœ"""
        
        # 1. ç»˜åˆ¶å§¿åŠ¿å’Œéª¨éª¼
        output_frame = self.pose_visualizer.draw_landmarks(
            processed_frame, 
            pose_result.landmarks, 
            pose_result.connections
        )
        
        # 2. ç»˜åˆ¶è·ç¦»ä¿¡æ¯
        output_frame = self.distance_visualizer.draw_distance_info(
            output_frame, 
            distance_result, 
            (pose_result.frame_width, pose_result.frame_height)
        )
        
        # 3. ç»˜åˆ¶æ‰‹åŠ¿ä¿¡æ¯
        # é’ˆå¯¹ gesture_result å¯¹è±¡è¿›è¡Œå¤„ç†ï¼Œç¡®ä¿ draw_gesture æ¥æ”¶åˆ°æ­£ç¡®çš„æ•°æ®ç»“æ„
        # å‡è®¾ GestureVisualizer å¯ä»¥æ¥æ”¶ GestureResult å¯¹è±¡ï¼Œå¦‚æœä¸èƒ½ï¼Œéœ€è¦åœ¨è¿™é‡Œæ·»åŠ  to_dict() è½¬æ¢
        # ç”±äºæ‚¨è¯´ä¹‹å‰æ²¡æœ‰é—®é¢˜ï¼Œè¿™é‡Œä¿æŒè°ƒç”¨ä¸å˜ï¼Œä¾èµ– Visualizer æ¨¡å—çš„å…¼å®¹æ€§
        output_frame = self.gesture_visualizer.draw_gesture(
            output_frame, 
            gesture_result, 
            self.current_command
        )
        
        # 4. ç»˜åˆ¶FPSå’Œç³»ç»Ÿä¿¡æ¯
        output_frame = self._show_statistics(output_frame)
        
        # 5. ç»˜åˆ¶è´¨é‡/è­¦å‘Šä¿¡æ¯ (å¦‚æœéœ€è¦)
        if not quality.get('valid', True):
            # è¿™æ˜¯ä¸€ä¸ªè¡¥å……ï¼Œä¸»è¦è­¦å‘Šåœ¨ process_frame ä¸­è¿”å›
            cv2.putText(output_frame, "LOW QUALITY WARNING", (10, 50), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)

        return output_frame

    def _show_statistics(self, frame: np.ndarray) -> np.ndarray:
        """åœ¨å¸§ä¸Šæ˜¾ç¤ºFPSå’Œç³»ç»Ÿä¿¡æ¯"""
        fps = self.camera_capture.get_fps()
        info = f"FPS: {fps:.2f} | Command: {self.current_command.upper()}"
        
        cv2.putText(frame, info, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
        
        return frame
    
    def _draw_error_frame(self, frame: np.ndarray, error_message: str) -> np.ndarray:
        """ç»˜åˆ¶ä¸€ä¸ªçº¢è‰²çš„é”™è¯¯æ¡†"""
        h, w, _ = frame.shape
        # ç»˜åˆ¶çº¢è‰²èƒŒæ™¯
        cv2.rectangle(frame, (0, h-50), (w, h), (0, 0, 200), -1)
        text = f"ERROR: {error_message[:40]}..."
        cv2.putText(frame, text, (10, h-15), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        return frame
        
    def _draw_enhanced_quality_warning(self, frame: np.ndarray, quality: Dict[str, Any]) -> np.ndarray:
        """ç»˜åˆ¶å¢å¼ºçš„å›¾åƒè´¨é‡è­¦å‘Š"""
        h, w, _ = frame.shape
        cv2.rectangle(frame, (0, h-80), (w, h), (0, 165, 255), -1) # æ©™è‰²èƒŒæ™¯
        
        warning_msg = f"Low Quality: {quality.get('reason', 'Unknown').upper()}"
        cv2.putText(frame, warning_msg, (10, h-50), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(frame, "Please improve lighting/focus.", (10, h-20), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        return frame

    def _draw_enhanced_no_person_warning(self, frame: np.ndarray) -> np.ndarray:
        """ç»˜åˆ¶å¢å¼ºçš„æœªæ£€æµ‹åˆ°äººä½“çš„è­¦å‘Š"""
        h, w, _ = frame.shape
        cv2.rectangle(frame, (0, 0), (w, 50), (0, 0, 255), -1) # çº¢è‰²èƒŒæ™¯
        
        cv2.putText(frame, "NO PERSON DETECTED", (10, 35), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        return frame
    
    

    def _execute_command(self, command: str):
        """æ‰§è¡Œå…·ä½“çš„æ§åˆ¶å‘½ä»¤ (åœ¨å›¾ç‰‡é›†æ¨¡å¼ä¸­ï¼Œåªåšæ‰“å°)"""
        print(f"\n[COMMAND EXECUTED] -> {command.upper()}")
        # å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨æ— äººæœºAPIã€æœºå™¨äººæ§åˆ¶ç­‰
        pass

    def start(self):
        """å¯åŠ¨ç³»ç»Ÿ (ç°åœ¨æ˜¯å¯åŠ¨å›¾ç‰‡é›†è¯»å–)"""
        print("å¯åŠ¨å›¾ç‰‡é›†è¯»å–...")
        # ã€ä¿®æ”¹ç‚¹ 3ã€‘ï¼šè°ƒç”¨ ImageSetCapture çš„ start
        if not self.camera_capture.start():
            print("âŒ å›¾ç‰‡é›†å¯åŠ¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥è·¯å¾„å’Œæ–‡ä»¶ã€‚")
            return False
        
        self.is_running = True
        print("âœ… ç³»ç»Ÿå¯åŠ¨æˆåŠŸ")
        return True

    def stop(self):
        """åœæ­¢ç³»ç»Ÿ"""
        self.is_running = False
        if self.camera_capture:
            self.camera_capture.stop()
        if self.image_visualizer:
            # ç”±äºæ˜¯å›¾ç‰‡é›†å¤„ç†ï¼Œä¸éœ€è¦ waitKeyï¼Œä½†å¯ä»¥ä¿ç•™ close_all ä¹ æƒ¯
            self.image_visualizer.close_all() 
        print("ç³»ç»Ÿå·²åœæ­¢")

    def run(self):
        """è¿è¡Œä¸»å¾ªç¯ - éå†å›¾ç‰‡é›†"""
        if not self.start():
            return
            
        print("\n" + "=" * 60)
        print(f" Â ç»¼åˆæ‰‹åŠ¿æ§åˆ¶ç³»ç»Ÿæ¼”ç¤º (å›¾ç‰‡é›†æ¨¡å¼: {self.camera_capture.num_frames} å¼ å›¾ç‰‡)")
        print("=" * 60)
        print("æ§åˆ¶é”®:")
        print(" Â 'q' æˆ– 'ESC' - é€€å‡ºç¨‹åº")
        print(" Â <ä»»ä½•å…¶ä»–é”®> - å¤„ç†ä¸‹ä¸€å¼ å›¾ç‰‡") # ã€ä¿®æ”¹ç‚¹ 4ã€‘ï¼šç­‰å¾…ç”¨æˆ·æŒ‰é”®å¤„ç†ä¸‹ä¸€å¼ å›¾ç‰‡
        print("=" * 60)
            
        try:
            while self.is_running:
                # å¤„ç†ä¸€å¸§
                output_frame = self.process_frame()
                
                # ã€ä¿®æ”¹ç‚¹ 5ã€‘ï¼šå¦‚æœ output_frame ä¸º Noneï¼Œè¡¨ç¤ºå›¾ç‰‡é›†å·²å¤„ç†å®Œæ¯•
                if output_frame is None:
                    print("\nğŸ‰ æ‰€æœ‰å›¾ç‰‡å·²å¤„ç†å®Œæ¯•ï¼Œç³»ç»Ÿé€€å‡ºã€‚")
                    break
                
                self.frame_count += 1
                
                # æ˜¾ç¤ºç»“æœ
                # åœ¨å›¾ç‰‡é›†æ¨¡å¼ä¸‹ï¼Œæˆ‘ä»¬ä½¿ç”¨ waitKey(0) æ¥å®ç°æŒ‰ä»»æ„é”®ç»§ç»­
                key = self.image_visualizer.show_image(output_frame, "Gesture Control System")
                
                # å¤„ç†æŒ‰é”®
                if key == ord('q') or key == 27: # q æˆ– ESC é€€å‡º
                    break
                elif key != -1: # ä»»ä½•å…¶ä»–é”®éƒ½ç»§ç»­ï¼Œå› ä¸º waitKey(0) é»˜è®¤ç­‰å¾…
                    pass 
                
        except KeyboardInterrupt:
            print("\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            print(f"è¿è¡Œé”™è¯¯: {e}")
            logger.error(f"è¿è¡Œé”™è¯¯: {e}")
        finally:
            self.stop()

    def process_frame(self):
        """å¤„ç†å•å¸§å›¾åƒ (é€»è¾‘ä¸å˜ï¼Œä½†ç°åœ¨è¾“å…¥æ¥è‡ªæ–‡ä»¶)"""
        frame = None
        try:
            # 1. è·å–å›¾åƒ - ImageSetCapture ä¼šè¯»å–ä¸‹ä¸€å¼ å›¾ç‰‡
            frame = self.camera_capture.get_frame()
            if frame is None:
                return None
            
            # ... (ä»¥ä¸‹é€»è¾‘ä¸æ‘„åƒå¤´æ¨¡å¼ä¿æŒä¸€è‡´) ...
            
            # 2. å›¾åƒé¢„å¤„ç†
            processed_frame = self.image_processor.preprocess(frame)
            
            # 3. å›¾åƒè´¨é‡è¯„ä¼°
            quality = self.quality_assessor.assess_quality(processed_frame)
            
            if not quality.get('valid', True):
                warning_frame = self._draw_enhanced_quality_warning(processed_frame, quality)
                return warning_frame
            
            # 4. å§¿åŠ¿æ£€æµ‹
            pose_result = self.pose_detector.detect(processed_frame)
            
            if not pose_result.landmarks:
                no_person_frame = self._draw_enhanced_no_person_warning(processed_frame)
                return no_person_frame
            
            # 5. è·ç¦»ä¼°ç®—
            distance_result = self.distance_estimator.estimate_distance(
                pose_result.landmarks,
                pose_result.frame_width,
                pose_result.frame_height
            )
            
            # 6. æ‰‹åŠ¿è¯†åˆ«
            frame_info = {
                'width': pose_result.frame_width,
                'height': pose_result.frame_height
            }
            # gesture_result æ˜¯ GestureResult å¯¹è±¡
            gesture_result = self.gesture_recognizer.recognize(
                pose_result.landmarks, frame_info
            )
            
            # 7. å¤„ç†æ§åˆ¶æŒ‡ä»¤ (è¿™é‡Œä¿®å¤äº†è°ƒç”¨é—®é¢˜)
            self._process_control_command(gesture_result, distance_result)
            
            # 8. å¯è§†åŒ–ç»“æœ
            output_frame = self._create_visualization(
                processed_frame, pose_result, distance_result, gesture_result, quality
            )
            
            return output_frame
            
        except Exception as e:
            logger.error(f"å¸§å¤„ç†é”™è¯¯: {e}")
            # ç¡®ä¿åœ¨å‡ºé”™æ—¶ï¼Œå³ä½¿ frame æ˜¯ None ä¹Ÿèƒ½è¿”å›ä¸€ä¸ªé»‘è‰²çš„é”™è¯¯æ¡†
            error_frame = frame if frame is not None else np.zeros((self.height, self.width, 3), dtype=np.uint8)
            return self._draw_error_frame(error_frame, str(e))

    def _handle_key_input(self, key):
        """å¤„ç†é”®ç›˜è¾“å…¥ - ä»…ç”¨äºæ¨¡å¼åˆ‡æ¢ï¼Œä¸æ§åˆ¶å¾ªç¯"""
        if key == ord('q'):
            return True
        # ... (å…¶ä»–é”®å¤„ç†) ...
        return False

# =================================================================
# ã€ä¸»æ‰§è¡Œå—ã€‘ï¼šä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°ä¼ å…¥å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„ (ä¿æŒä¸å˜)
# =================================================================

if __name__ == '__main__':
    
    # ã€ä¿®æ”¹ç‚¹ 6ã€‘ï¼šä½¿ç”¨ argparse æ¥æ”¶æ–‡ä»¶å¤¹è·¯å¾„
    parser = argparse.ArgumentParser(description="æ‰‹åŠ¿è¯†åˆ«æ§åˆ¶ç³»ç»Ÿ - å›¾ç‰‡é›†æ¨¡å¼")
    parser.add_argument('--folder_path', type=str, required=True, 
                        help='åŒ…å«å¾…å¤„ç†å›¾ç‰‡ (JPG/PNG/BMP) çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚')
    parser.add_argument('--width', type=int, default=640, help='å¤„ç†å›¾åƒå®½åº¦ (é»˜è®¤ä¸º 640)ã€‚')
    parser.add_argument('--height', type=int, default=480, help='å¤„ç†å›¾åƒé«˜åº¦ (é»˜è®¤ä¸º 480)ã€‚')
    args = parser.parse_args()
    
    try:
        # ã€ä¿®æ”¹ç‚¹ 7ã€‘ï¼šä½¿ç”¨ folder_path å®ä¾‹åŒ–ç³»ç»Ÿ
        system = GestureControlSystem(
            folder_path=args.folder_path, 
            width=args.width, 
            height=args.height
        )
        system.run()
    except Exception as e:
        logger.critical(f"ç³»ç»Ÿå¯åŠ¨å¤±è´¥æˆ–å‘ç”Ÿè‡´å‘½é”™è¯¯: {e}")
        sys.exit(1)